"""
æ··åˆæ¶æ„RAGç³»ç»Ÿå®Œæ•´æ¼”ç¤º
æ•´åˆæ‰€æœ‰æ¨¡å—çš„ç»¼åˆä½¿ç”¨ç¤ºä¾‹
"""

import os
import sys
from typing import List, Dict, Any
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from langchain_llamaindex_hybrid import HybridRAGSystem
from llama_packs_integration import LlamaPacksEnhancedRAG
from hybrid_performance_optimizer import HybridRAGOptimizer


class HybridRAGDemo:
    """æ··åˆRAGç³»ç»Ÿæ¼”ç¤ºç±»"""
    
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        """åˆå§‹åŒ–æ¼”ç¤ºç³»ç»Ÿ"""
        print("=== åˆå§‹åŒ–æ··åˆRAGæ¼”ç¤ºç³»ç»Ÿ ===")
        
        # æ ¸å¿ƒç³»ç»Ÿç»„ä»¶
        self.hybrid_rag = HybridRAGSystem(model_name=model_name)
        self.packs_rag = LlamaPacksEnhancedRAG(model_name=model_name)
        self.optimizer = None  # åœ¨æ„å»ºçŸ¥è¯†åº“ååˆå§‹åŒ–
        
        # æ¼”ç¤ºé…ç½®
        self.demo_config = {
            "test_queries": [
                "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
                "æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
                "å·ç§¯ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
                "å¦‚ä½•è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ï¼Ÿ"
            ],
            "documents_path": "./documents/",
            "enable_optimization": True,
            "show_detailed_output": True
        }
        
        print("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
    def setup_demo_environment(self):
        """è®¾ç½®æ¼”ç¤ºç¯å¢ƒ"""
        print("\n=== è®¾ç½®æ¼”ç¤ºç¯å¢ƒ ===")
        
        # æ£€æŸ¥APIå¯†é’¥
        if not os.getenv("OPENAI_API_KEY"):
            print("è­¦å‘Š: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            print("è¯·è®¾ç½®APIå¯†é’¥: export OPENAI_API_KEY='your-api-key'")
            return False
            
        # æ£€æŸ¥æ–‡æ¡£ç›®å½•
        docs_path = self.demo_config["documents_path"]
        if not os.path.exists(docs_path):
            print(f"åˆ›å»ºæ–‡æ¡£ç›®å½•: {docs_path}")
            os.makedirs(docs_path, exist_ok=True)
            
            # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
            self._create_sample_documents(docs_path)
            
        print("æ¼”ç¤ºç¯å¢ƒè®¾ç½®å®Œæˆ")
        return True
        
    def _create_sample_documents(self, docs_path: str):
        """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£"""
        sample_docs = {
            "machine_learning_basics.txt": """
æœºå™¨å­¦ä¹ åŸºç¡€çŸ¥è¯†

æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚

ä¸»è¦ç±»å‹ï¼š
1. ç›‘ç£å­¦ä¹ ï¼šä½¿ç”¨æ ‡è®°æ•°æ®è¿›è¡Œè®­ç»ƒ
2. æ— ç›‘ç£å­¦ä¹ ï¼šä»æœªæ ‡è®°æ•°æ®ä¸­å‘ç°æ¨¡å¼
3. å¼ºåŒ–å­¦ä¹ ï¼šé€šè¿‡å¥–åŠ±å’Œæƒ©ç½šæœºåˆ¶å­¦ä¹ 

å¸¸è§ç®—æ³•ï¼š
- çº¿æ€§å›å½’
- å†³ç­–æ ‘
- æ”¯æŒå‘é‡æœº
- ç¥ç»ç½‘ç»œ

åº”ç”¨é¢†åŸŸï¼š
- å›¾åƒè¯†åˆ«
- è‡ªç„¶è¯­è¨€å¤„ç†
- æ¨èç³»ç»Ÿ
- åŒ»ç–—è¯Šæ–­
            """,
            
            "deep_learning_guide.txt": """
æ·±åº¦å­¦ä¹ æŒ‡å—

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼ŒåŸºäºäººå·¥ç¥ç»ç½‘ç»œã€‚

æ ¸å¿ƒæ¦‚å¿µï¼š
- å¤šå±‚ç¥ç»ç½‘ç»œ
- åå‘ä¼ æ’­ç®—æ³•
- æ¿€æ´»å‡½æ•°
- æ¢¯åº¦ä¸‹é™ä¼˜åŒ–

ä¸»è¦æ¶æ„ï¼š
1. å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼šæ“…é•¿å›¾åƒå¤„ç†
2. å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼šé€‚åˆåºåˆ—æ•°æ®
3. é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰ï¼šè§£å†³é•¿åºåˆ—é—®é¢˜
4. Transformerï¼šç°ä»£NLPçš„åŸºç¡€

ä¼˜åŠ¿ï¼š
- è‡ªåŠ¨ç‰¹å¾æå–
- å¤„ç†å¤§è§„æ¨¡æ•°æ®
- åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚

æŒ‘æˆ˜ï¼š
- éœ€è¦å¤§é‡æ•°æ®
- è®¡ç®—èµ„æºè¦æ±‚é«˜
- æ¨¡å‹å¯è§£é‡Šæ€§å·®
            """,
            
            "model_evaluation.txt": """
æœºå™¨å­¦ä¹ æ¨¡å‹è¯„ä¼°

æ¨¡å‹è¯„ä¼°æ˜¯æœºå™¨å­¦ä¹ é¡¹ç›®çš„å…³é”®ç¯èŠ‚ã€‚

è¯„ä¼°æŒ‡æ ‡ï¼š

åˆ†ç±»ä»»åŠ¡ï¼š
- å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
- ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰
- å¬å›ç‡ï¼ˆRecallï¼‰
- F1åˆ†æ•°
- AUC-ROCæ›²çº¿

å›å½’ä»»åŠ¡ï¼š
- å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
- å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
- RÂ²å†³å®šç³»æ•°

äº¤å‰éªŒè¯ï¼š
- KæŠ˜äº¤å‰éªŒè¯
- ç•™ä¸€æ³•
- æ—¶é—´åºåˆ—åˆ†å‰²

è¿‡æ‹Ÿåˆæ£€æµ‹ï¼š
- è®­ç»ƒé›†ä¸æµ‹è¯•é›†æ€§èƒ½å¯¹æ¯”
- å­¦ä¹ æ›²çº¿åˆ†æ
- æ­£åˆ™åŒ–æŠ€æœ¯

æœ€ä½³å®è·µï¼š
1. æ•°æ®é¢„å¤„ç†çš„é‡è¦æ€§
2. ç‰¹å¾é€‰æ‹©å’Œå·¥ç¨‹
3. è¶…å‚æ•°è°ƒä¼˜
4. æ¨¡å‹è§£é‡Šå’Œå¯è§†åŒ–
            """
        }
        
        for filename, content in sample_docs.items():
            file_path = os.path.join(docs_path, filename)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content.strip())
                
        print(f"åˆ›å»ºäº† {len(sample_docs)} ä¸ªç¤ºä¾‹æ–‡æ¡£")
        
    def build_knowledge_base(self, documents_path: str = None) -> Dict[str, Any]:
        """æ„å»ºçŸ¥è¯†åº“"""
        if documents_path is None:
            documents_path = self.demo_config["documents_path"]
            
        print(f"\n=== æ„å»ºçŸ¥è¯†åº“: {documents_path} ===")
        
        try:
            # æ„å»ºæ··åˆæ¶æ„çŸ¥è¯†åº“
            hybrid_build_info = self.hybrid_rag.build_knowledge_base(documents_path)
            print(f"æ··åˆæ¶æ„çŸ¥è¯†åº“: {hybrid_build_info}")
            
            # æ„å»ºLlama PacksçŸ¥è¯†åº“
            packs_build_info = self.packs_rag.build_knowledge_base(documents_path)
            print(f"Llama PacksçŸ¥è¯†åº“: {packs_build_info}")
            
            # åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–å™¨
            if self.demo_config["enable_optimization"]:
                self.optimizer = HybridRAGOptimizer(self.hybrid_rag)
                print("æ€§èƒ½ä¼˜åŒ–å™¨å·²åˆå§‹åŒ–")
            
            return {
                "hybrid_rag": hybrid_build_info,
                "packs_rag": packs_build_info,
                "optimizer_ready": self.optimizer is not None,
                "build_timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            return {"error": str(e)}
            
    def demo_basic_queries(self):
        """æ¼”ç¤ºåŸºç¡€æŸ¥è¯¢åŠŸèƒ½"""
        print(f"\n=== åŸºç¡€æŸ¥è¯¢æ¼”ç¤º ===")
        
        test_queries = self.demo_config["test_queries"][:2]  # åªæµ‹è¯•å‰2ä¸ª
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n--- æŸ¥è¯¢ {i}: {query} ---")
            
            try:
                # æ··åˆæ¶æ„æŸ¥è¯¢
                result = self.hybrid_rag.smart_query(query)
                
                print(f"å›ç­”: {result['answer'][:200]}...")
                print(f"ç½®ä¿¡åº¦: {result['confidence']}")
                print(f"å¤„ç†æ—¶é—´: {result['processing_time']}ç§’")
                print(f"æ£€ç´¢æ–‡æ¡£æ•°: {result['retrieved_docs_count']}")
                
                if self.demo_config["show_detailed_output"]:
                    print(f"æ¥æºä¿¡æ¯: {len(result['sources'])} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
                    
            except Exception as e:
                print(f"æŸ¥è¯¢å¤±è´¥: {e}")
                
    def demo_llama_packs_features(self):
        """æ¼”ç¤ºLlama PacksåŠŸèƒ½"""
        print(f"\n=== Llama Packs åŠŸèƒ½æ¼”ç¤º ===")
        
        test_query = self.demo_config["test_queries"][0]
        print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        try:
            # Agent Searchæ¼”ç¤º
            print(f"\n--- Agent Searchæ–¹æ³• ---")
            agent_result = self.packs_rag.agent_search_query(test_query)
            if "error" not in agent_result:
                print(f"Agentæœç´¢ç­–ç•¥: {agent_result.get('search_strategy', 'N/A')}")
                print(f"ç½®ä¿¡åº¦: {agent_result.get('confidence', 'N/A')}")
                print(f"å¤„ç†æ—¶é—´: {agent_result.get('processing_time', 'N/A')}ç§’")
            
            # Fusion Retrievalæ¼”ç¤º
            print(f"\n--- Fusion Retrievalæ–¹æ³• ---")
            fusion_result = self.packs_rag.fusion_retrieval_query(test_query)
            if "error" not in fusion_result:
                print(f"èåˆæŸ¥è¯¢æ•°: {len(fusion_result.get('fusion_queries', []))}")
                print(f"èåˆåˆ†æ•°: {fusion_result.get('fusion_score', 'N/A')}")
                print(f"ç½®ä¿¡åº¦: {fusion_result.get('confidence', 'N/A')}")
                
            # å¤šPackå¯¹æ¯”
            print(f"\n--- å¤šPackæ–¹æ³•å¯¹æ¯” ---")
            comparison = self.packs_rag.multi_pack_comparison(test_query)
            
            if "error" not in comparison:
                perf = comparison["performance_analysis"]
                print(f"æœ€å¿«æ–¹æ³•: {perf['fastest_method']}")
                print(f"æœ€é«˜ç½®ä¿¡åº¦æ–¹æ³•: {perf['most_confident']}")
                print(f"å¹³å‡å¤„ç†æ—¶é—´: {perf['avg_processing_time']}ç§’")
                print(f"æ€»å¤„ç†æ—¶é—´: {comparison['total_processing_time']}ç§’")
                
        except Exception as e:
            print(f"Llama Packsæ¼”ç¤ºå¤±è´¥: {e}")
            
    def demo_performance_optimization(self):
        """æ¼”ç¤ºæ€§èƒ½ä¼˜åŒ–åŠŸèƒ½"""
        if not self.optimizer:
            print("æ€§èƒ½ä¼˜åŒ–å™¨æœªå¯ç”¨")
            return
            
        print(f"\n=== æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º ===")
        
        # æ€§èƒ½æµ‹é‡
        test_query = self.demo_config["test_queries"][0]
        print(f"æ€§èƒ½æµ‹é‡æŸ¥è¯¢: {test_query}")
        
        try:
            # æµ‹é‡åŸºå‡†æ€§èƒ½
            print(f"\n--- åŸºå‡†æ€§èƒ½æµ‹é‡ ---")
            baseline_metrics = self.optimizer.measure_performance(test_query)
            print(f"æŸ¥è¯¢æ—¶é—´: {baseline_metrics.query_time:.3f}ç§’")
            print(f"ç½®ä¿¡åº¦: {baseline_metrics.confidence}")
            print(f"å†…å­˜ä½¿ç”¨: {baseline_metrics.memory_usage:.2f}MB")
            
            # ç¼“å­˜æŸ¥è¯¢æ¼”ç¤º
            print(f"\n--- ç¼“å­˜æŸ¥è¯¢æ¼”ç¤º ---")
            cached_result = self.optimizer.cached_query(test_query)
            print(f"ç¼“å­˜å‘½ä¸­: {cached_result.get('cache_hit', False)}")
            
            # å†æ¬¡æŸ¥è¯¢åŒæ ·é—®é¢˜ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰
            cached_result2 = self.optimizer.cached_query(test_query)
            print(f"ç¬¬äºŒæ¬¡æŸ¥è¯¢ç¼“å­˜å‘½ä¸­: {cached_result2.get('cache_hit', False)}")
            
            # å¹¶è¡ŒæŸ¥è¯¢æ¼”ç¤º
            print(f"\n--- å¹¶è¡ŒæŸ¥è¯¢æ¼”ç¤º ---")
            parallel_queries = self.demo_config["test_queries"][:3]
            parallel_results = self.optimizer.parallel_batch_query(parallel_queries)
            
            successful_queries = [r for r in parallel_results if "error" not in r]
            print(f"å¹¶è¡ŒæŸ¥è¯¢å®Œæˆ: {len(successful_queries)}/{len(parallel_queries)} æˆåŠŸ")
            
            # æ€§èƒ½æŠ¥å‘Š
            print(f"\n--- æ€§èƒ½æŠ¥å‘Š ---")
            performance_report = self.optimizer.get_performance_report()
            
            if "message" not in performance_report:
                stats = performance_report["performance_stats"]
                print(f"æ€»æŸ¥è¯¢æ¬¡æ•°: {performance_report['total_queries']}")
                print(f"å¹³å‡æŸ¥è¯¢æ—¶é—´: {stats['avg_query_time']}ç§’")
                print(f"å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence']}")
                print(f"ç¼“å­˜æ¡ç›®æ•°: {performance_report['cache_stats']['cache_entries']}")
                
                # ä¼˜åŒ–å»ºè®®
                recommendations = self.optimizer.smart_optimization_recommendation()
                if recommendations.get("recommendations"):
                    print(f"\nä¼˜åŒ–å»ºè®®æ•°é‡: {len(recommendations['recommendations'])}")
                    print(f"ä¼˜åŒ–ä¼˜å…ˆçº§: {recommendations['optimization_priority']}")
                    
        except Exception as e:
            print(f"æ€§èƒ½ä¼˜åŒ–æ¼”ç¤ºå¤±è´¥: {e}")
            
    def run_comprehensive_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸš€ æ··åˆæ¶æ„RAGç³»ç»Ÿç»¼åˆæ¼”ç¤ºå¼€å§‹")
        print("=" * 50)
        
        # 1. ç¯å¢ƒè®¾ç½®
        if not self.setup_demo_environment():
            print("âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œæ¼”ç¤ºç»ˆæ­¢")
            return
            
        # 2. çŸ¥è¯†åº“æ„å»º
        build_result = self.build_knowledge_base()
        if "error" in build_result:
            print(f"âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {build_result['error']}")
            return
            
        print("âœ… çŸ¥è¯†åº“æ„å»ºæˆåŠŸ")
        
        # 3. åŸºç¡€æŸ¥è¯¢æ¼”ç¤º
        self.demo_basic_queries()
        
        # 4. Llama PacksåŠŸèƒ½æ¼”ç¤º
        self.demo_llama_packs_features()
        
        # 5. æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º
        if self.demo_config["enable_optimization"]:
            self.demo_performance_optimization()
            
        # 6. æ¼”ç¤ºæ€»ç»“
        self._demo_summary()
        
        print("\nğŸ‰ æ··åˆæ¶æ„RAGç³»ç»Ÿæ¼”ç¤ºå®Œæˆ")
        print("=" * 50)
        
    def _demo_summary(self):
        """æ¼”ç¤ºæ€»ç»“"""
        print(f"\n=== æ¼”ç¤ºæ€»ç»“ ===")
        
        summary_stats = {
            "ç³»ç»Ÿç»„ä»¶": "LangChain + LlamaIndex æ··åˆæ¶æ„",
            "Llama Packs": "4ç§å¢å¼ºæ–¹æ³•ï¼ˆAgent Searchã€Fusion Retrievalç­‰ï¼‰",
            "æ€§èƒ½ä¼˜åŒ–": "ç¼“å­˜ã€å¹¶è¡Œå¤„ç†ã€è‡ªé€‚åº”å‚æ•°è°ƒä¼˜",
            "æµ‹è¯•æŸ¥è¯¢": len(self.demo_config["test_queries"]),
            "æ¼”ç¤ºæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        for key, value in summary_stats.items():
            print(f"{key}: {value}")
            
        print(f"\nğŸ’¡ æ ¸å¿ƒä¼˜åŠ¿:")
        print("- ç»“åˆLangChainå·¥ä½œæµæ§åˆ¶å’ŒLlamaIndexæ£€ç´¢ä¼˜åŒ–")
        print("- ä¸°å¯Œçš„Llama Packsç”Ÿæ€å·¥å…·")
        print("- æ™ºèƒ½æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–")
        print("- ä¼ä¸šçº§ç¼“å­˜å’Œå¹¶è¡Œå¤„ç†")


# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    print("æ··åˆæ¶æ„RAGç³»ç»Ÿæ¼”ç¤ºç¨‹åº")
    print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–å¹¶è®¾ç½®OpenAI APIå¯†é’¥")
    
    try:
        # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
        demo = HybridRAGDemo(model_name="gpt-3.5-turbo")
        
        # è¿è¡Œå®Œæ•´æ¼”ç¤º
        demo.run_comprehensive_demo()
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­æ¼”ç¤º")
    except Exception as e:
        print(f"\n\næ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–å®‰è£…å’ŒAPIé…ç½®")
    finally:
        print("\næ„Ÿè°¢ä½¿ç”¨æ··åˆæ¶æ„RAGç³»ç»Ÿæ¼”ç¤ºï¼")
        
    # æä¾›äº¤äº’å¼æŸ¥è¯¢é€‰é¡¹
    print("\n" + "="*50)
    print("ğŸ’¡ æƒ³è¦äº¤äº’å¼ä½“éªŒï¼Ÿ")
    print("å¯ä»¥å¯¼å…¥ HybridRAGDemo ç±»è¿›è¡Œè‡ªå®šä¹‰æŸ¥è¯¢ï¼š")
    print("""
from demo import HybridRAGDemo

demo = HybridRAGDemo()
demo.setup_demo_environment()
demo.build_knowledge_base()

# è‡ªå®šä¹‰æŸ¥è¯¢
result = demo.hybrid_rag.smart_query("ä½ çš„é—®é¢˜")
print(result['answer'])
    """)