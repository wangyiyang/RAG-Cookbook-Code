"""
RAG+Agentèåˆç³»ç»Ÿæ¼”ç¤º
å®Œæ•´å±•ç¤ºGraphRAGã€RAPTORå’ŒAgentå¢å¼ºRAGçš„é›†æˆåº”ç”¨
"""

import sys
import traceback
from typing import Dict, List, Any
import time

# å¯¼å…¥å„ä¸ªæ¨¡å—
from graph_rag import GraphRAGSystem, MockLLM as GraphMockLLM, MockEmbeddingModel as GraphMockEmbedding
from raptor_tree import RAPTORTree, MockLLM as RaptorMockLLM, MockEmbeddingModel as RaptorMockEmbedding
from agent_enhanced_rag import AgentEnhancedRAG, MockLLM as AgentMockLLM, MockRetriever, MockEmbeddingModel as AgentMockEmbedding

class IntegratedRAGSystem:
    """é›†æˆçš„RAG+Agentç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–é›†æˆç³»ç»Ÿ"""
        print("æ­£åœ¨åˆå§‹åŒ–é›†æˆRAG+Agentç³»ç»Ÿ...")
        
        try:
            # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
            self.graph_llm = GraphMockLLM()
            self.graph_embedding = GraphMockEmbedding()
            self.graph_rag = GraphRAGSystem(self.graph_llm, self.graph_embedding)
            
            self.raptor_llm = RaptorMockLLM()
            self.raptor_embedding = RaptorMockEmbedding()
            self.raptor_tree = RAPTORTree(self.raptor_llm, self.raptor_embedding, max_cluster_size=5)
            
            self.agent_llm = AgentMockLLM()
            self.agent_retriever = MockRetriever()
            self.agent_embedding = AgentMockEmbedding()
            self.agent_rag = AgentEnhancedRAG(self.agent_llm, self.agent_retriever, self.agent_embedding)
            
            # ç³»ç»ŸçŠ¶æ€
            self.is_initialized = False
            self.knowledge_base_size = 0
            
            print("âœ… é›†æˆç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def setup_knowledge_base(self, documents: List[Dict]) -> Dict:
        """è®¾ç½®çŸ¥è¯†åº“"""
        
        if not documents:
            raise ValueError("æ–‡æ¡£åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        setup_results = {
            'graph_rag_status': 'pending',
            'raptor_status': 'pending',
            'total_documents': len(documents),
            'setup_time': 0,
            'errors': []
        }
        
        start_time = time.time()
        
        try:
            print(f"\nğŸ”„ å¼€å§‹æ„å»ºçŸ¥è¯†åº“ï¼Œæ–‡æ¡£æ•°é‡: {len(documents)}")
            
            # 1. æ„å»ºGraphRAGçŸ¥è¯†å›¾è°±
            print("\nğŸ“Š æ„å»ºGraphRAGçŸ¥è¯†å›¾è°±...")
            try:
                self.graph_rag.build_knowledge_graph(documents)
                setup_results['graph_rag_status'] = 'success'
                print("âœ… GraphRAGçŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ")
            except Exception as e:
                setup_results['graph_rag_status'] = 'failed'
                setup_results['errors'].append(f"GraphRAGæ„å»ºå¤±è´¥: {e}")
                print(f"âŒ GraphRAGæ„å»ºå¤±è´¥: {e}")
            
            # 2. æ„å»ºRAPTORæ ‘
            print("\nğŸŒ² æ„å»ºRAPTORåˆ†å±‚æ ‘...")
            try:
                self.raptor_tree.build_raptor_tree(documents)
                setup_results['raptor_status'] = 'success'
                print("âœ… RAPTORæ ‘æ„å»ºå®Œæˆ")
            except Exception as e:
                setup_results['raptor_status'] = 'failed'
                setup_results['errors'].append(f"RAPTORæ„å»ºå¤±è´¥: {e}")
                print(f"âŒ RAPTORæ„å»ºå¤±è´¥: {e}")
            
            self.knowledge_base_size = len(documents)
            self.is_initialized = True
            
            setup_results['setup_time'] = time.time() - start_time
            
            print(f"\nâœ… çŸ¥è¯†åº“è®¾ç½®å®Œæˆï¼Œè€—æ—¶: {setup_results['setup_time']:.2f}ç§’")
            
            return setup_results
            
        except Exception as e:
            setup_results['errors'].append(f"çŸ¥è¯†åº“è®¾ç½®å¤±è´¥: {e}")
            print(f"âŒ çŸ¥è¯†åº“è®¾ç½®å¤±è´¥: {e}")
            return setup_results
    
    def multi_modal_query(self, query: str, user_context: Dict = None, 
                         use_graph_rag: bool = True, 
                         use_raptor: bool = True, 
                         use_agent: bool = True) -> Dict:
        """å¤šæ¨¡å¼æŸ¥è¯¢å¤„ç†"""
        
        if not self.is_initialized:
            return {
                'error': 'ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè®¾ç½®çŸ¥è¯†åº“',
                'suggestions': ['è°ƒç”¨setup_knowledge_base()æ–¹æ³•']
            }
        
        if not query or not query.strip():
            return {
                'error': 'æŸ¥è¯¢ä¸èƒ½ä¸ºç©º',
                'suggestions': ['è¯·æä¾›æœ‰æ•ˆçš„æŸ¥è¯¢å†…å®¹']
            }
        
        user_context = user_context or {
            'user_id': 'demo_user',
            'session_id': 'demo_session',
            'original_query': query
        }
        
        query_results = {
            'query': query,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'modes_used': [],
            'results': {},
            'final_answer': '',
            'confidence_scores': {},
            'execution_times': {},
            'errors': []
        }
        
        total_start_time = time.time()
        
        # 1. GraphRAGæŸ¥è¯¢
        if use_graph_rag:
            print(f"\nğŸ” GraphRAGçŸ¥è¯†å›¾è°±æŸ¥è¯¢...")
            try:
                graph_start = time.time()
                graph_result = self.graph_rag.generate_graph_augmented_answer(query)
                graph_time = time.time() - graph_start
                
                query_results['modes_used'].append('GraphRAG')
                query_results['results']['graph_rag'] = graph_result
                query_results['confidence_scores']['graph_rag'] = graph_result.get('confidence_score', 0.0)
                query_results['execution_times']['graph_rag'] = graph_time
                
                print(f"âœ… GraphRAGæŸ¥è¯¢å®Œæˆï¼Œè€—æ—¶: {graph_time:.2f}ç§’")
                
            except Exception as e:
                error_msg = f"GraphRAGæŸ¥è¯¢å¤±è´¥: {e}"
                query_results['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
        
        # 2. RAPTORæŸ¥è¯¢
        if use_raptor:
            print(f"\nğŸŒ² RAPTORåˆ†å±‚æ ‘æŸ¥è¯¢...")
            try:
                raptor_start = time.time()
                raptor_result = self.raptor_tree.generate_raptor_answer(query)
                raptor_time = time.time() - raptor_start
                
                query_results['modes_used'].append('RAPTOR')
                query_results['results']['raptor'] = raptor_result
                query_results['confidence_scores']['raptor'] = raptor_result.get('confidence_score', 0.0)
                query_results['execution_times']['raptor'] = raptor_time
                
                print(f"âœ… RAPTORæŸ¥è¯¢å®Œæˆï¼Œè€—æ—¶: {raptor_time:.2f}ç§’")
                
            except Exception as e:
                error_msg = f"RAPTORæŸ¥è¯¢å¤±è´¥: {e}"
                query_results['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
        
        # 3. Agentå¢å¼ºRAGæŸ¥è¯¢
        if use_agent:
            print(f"\nğŸ¤– Agentå¢å¼ºRAGæŸ¥è¯¢...")
            try:
                agent_start = time.time()
                agent_result = self.agent_rag.enhanced_query_processing(query, user_context)
                agent_time = time.time() - agent_start
                
                query_results['modes_used'].append('Agent-RAG')
                query_results['results']['agent_rag'] = agent_result
                query_results['confidence_scores']['agent_rag'] = agent_result.get('confidence_score', 0.0)
                query_results['execution_times']['agent_rag'] = agent_time
                
                print(f"âœ… Agent-RAGæŸ¥è¯¢å®Œæˆï¼Œè€—æ—¶: {agent_time:.2f}ç§’")
                
            except Exception as e:
                error_msg = f"Agent-RAGæŸ¥è¯¢å¤±è´¥: {e}"
                query_results['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
        
        # 4. ç»“æœèåˆ
        query_results['final_answer'] = self._fuse_results(query_results['results'])
        query_results['total_execution_time'] = time.time() - total_start_time
        
        return query_results
    
    def _fuse_results(self, results: Dict) -> str:
        """èåˆå¤šæ¨¡å¼æŸ¥è¯¢ç»“æœ"""
        
        if not results:
            return "æŠ±æ­‰ï¼Œæ‰€æœ‰æŸ¥è¯¢æ¨¡å¼éƒ½æœªèƒ½æˆåŠŸæ‰§è¡Œã€‚"
        
        answers = []
        confidence_weights = []
        
        # æ”¶é›†å„æ¨¡å¼çš„ç­”æ¡ˆå’Œç½®ä¿¡åº¦
        for mode, result in results.items():
            if isinstance(result, dict) and 'answer' in result:
                answer = result['answer']
                confidence = result.get('confidence_score', 0.5)
                
                if answer and answer.strip():
                    answers.append(f"[{mode.upper()}] {answer}")
                    confidence_weights.append(confidence)
        
        if not answers:
            return "æŠ±æ­‰ï¼Œæœªèƒ½ä»ä»»ä½•æ¨¡å¼è·å–åˆ°æœ‰æ•ˆç­”æ¡ˆã€‚"
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªç­”æ¡ˆï¼Œç›´æ¥è¿”å›
        if len(answers) == 1:
            return answers[0]
        
        # å¤šç­”æ¡ˆèåˆç­–ç•¥ï¼šé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ç­”æ¡ˆï¼Œå¹¶æåŠå…¶ä»–è§‚ç‚¹
        best_index = confidence_weights.index(max(confidence_weights))
        best_answer = answers[best_index]
        
        # æ„å»ºèåˆç­”æ¡ˆ
        fused_answer = f"ç»¼åˆåˆ†æç»“æœï¼š\n\n{best_answer}\n\n"
        
        if len(answers) > 1:
            fused_answer += "å…¶ä»–è§‚ç‚¹å‚è€ƒï¼š\n"
            for i, answer in enumerate(answers):
                if i != best_index:
                    fused_answer += f"â€¢ {answer}\n"
        
        return fused_answer
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        
        status = {
            'is_initialized': self.is_initialized,
            'knowledge_base_size': self.knowledge_base_size,
            'components': {
                'graph_rag': {
                    'status': 'ready' if hasattr(self.graph_rag, 'knowledge_graph') else 'not_ready',
                    'nodes': self.graph_rag.knowledge_graph.number_of_nodes() if hasattr(self.graph_rag, 'knowledge_graph') else 0,
                    'edges': self.graph_rag.knowledge_graph.number_of_edges() if hasattr(self.graph_rag, 'knowledge_graph') else 0
                },
                'raptor_tree': {
                    'status': 'ready' if self.raptor_tree.nodes else 'not_ready',
                    'total_nodes': len(self.raptor_tree.nodes),
                    'root_nodes': len(self.raptor_tree.root_nodes)
                },
                'agent_rag': {
                    'status': 'ready',
                    'memory_records': len(self.agent_rag.memory.memories),
                    'registered_tools': len(self.agent_rag.tool_registry.tools)
                }
            }
        }
        
        return status


def run_comprehensive_demo():
    """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
    
    print("ğŸš€ å¯åŠ¨RAG+Agentèåˆç³»ç»Ÿå®Œæ•´æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # 1. åˆå§‹åŒ–ç³»ç»Ÿ
        system = IntegratedRAGSystem()
        
        # 2. å‡†å¤‡æµ‹è¯•æ–‡æ¡£
        test_documents = [
            {
                "id": "doc1",
                "title": "äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ ",
                "content": "äººå·¥æ™ºèƒ½(AI)æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒå­é¢†åŸŸï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ æ¨¡å¼ï¼Œè€Œæ— éœ€æ˜¾å¼ç¼–ç¨‹ã€‚æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªä¸“é—¨åˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚",
                "source": "AIåŸºç¡€æ•™ç¨‹"
            },
            {
                "id": "doc2",
                "title": "Transformeræ¶æ„è¯¦è§£",
                "content": "Transformeræ˜¯ä¸€ç§é©å‘½æ€§çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œäº2017å¹´åœ¨è®ºæ–‡ã€ŠAttention Is All You Needã€‹ä¸­é¦–æ¬¡æå‡ºã€‚å®ƒå®Œå…¨åŸºäºæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ‘’å¼ƒäº†ä¼ ç»Ÿçš„å¾ªç¯å’Œå·ç§¯ç»“æ„ã€‚Transformeræ¶æ„åŒ…å«ç¼–ç å™¨å’Œè§£ç å™¨ä¸¤éƒ¨åˆ†ï¼Œæ¯éƒ¨åˆ†éƒ½ç”±å¤šä¸ªç›¸åŒçš„å±‚å †å è€Œæˆã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶æ˜¯Transformerçš„æ ¸å¿ƒï¼Œå…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—æ—¶å…³æ³¨ä¸åŒä½ç½®çš„ä¿¡æ¯ã€‚",
                "source": "æ·±åº¦å­¦ä¹ è®ºæ–‡"
            },
            {
                "id": "doc3",
                "title": "å¤§è¯­è¨€æ¨¡å‹çš„å‘å±•",
                "content": "å¤§è¯­è¨€æ¨¡å‹(LLM)å¦‚GPTã€BERTç­‰åŸºäºTransformeræ¶æ„æ„å»ºï¼Œé€šè¿‡åœ¨å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒæ¥å­¦ä¹ è¯­è¨€çš„ç»Ÿè®¡è§„å¾‹ã€‚è¿™äº›æ¨¡å‹å±•ç°å‡ºäº†å¼ºå¤§çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œåœ¨é—®ç­”ã€æ–‡æœ¬æ‘˜è¦ã€ä»£ç ç”Ÿæˆç­‰ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æˆæœã€‚RAG(æ£€ç´¢å¢å¼ºç”Ÿæˆ)æŠ€æœ¯å°†æ£€ç´¢ç³»ç»Ÿä¸ç”Ÿæˆæ¨¡å‹ç»“åˆï¼Œé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºæ¨¡å‹çš„å›ç­”è´¨é‡ã€‚",
                "source": "AIå‰æ²¿æŠ€æœ¯"
            },
            {
                "id": "doc4",
                "title": "çŸ¥è¯†å›¾è°±ä¸RAGèåˆ",
                "content": "çŸ¥è¯†å›¾è°±æ˜¯ä¸€ç§ç»“æ„åŒ–çš„çŸ¥è¯†è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡å®ä½“ã€å…³ç³»å’Œå±æ€§æ¥ç»„ç»‡ä¿¡æ¯ã€‚GraphRAGå°†çŸ¥è¯†å›¾è°±æŠ€æœ¯ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆç›¸ç»“åˆï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„å…³ç³»æ¨ç†ä»»åŠ¡ã€‚RAPTORæŠ€æœ¯é€šè¿‡é€’å½’æŠ½è±¡å’Œèšç±»æ„å»ºåˆ†å±‚çš„æ–‡æ¡£è¡¨ç¤ºï¼Œæ”¯æŒä¸åŒç²’åº¦çš„ä¿¡æ¯æ£€ç´¢ã€‚Agentå¢å¼ºçš„RAGç³»ç»Ÿå…·å¤‡è‡ªä¸»å†³ç­–ã€è®°å¿†ç®¡ç†å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚",
                "source": "RAGæŠ€æœ¯è¿›å±•"
            }
        ]
        
        # 3. è®¾ç½®çŸ¥è¯†åº“
        print("\nğŸ“š è®¾ç½®çŸ¥è¯†åº“...")
        setup_result = system.setup_knowledge_base(test_documents)
        
        print(f"\nğŸ“Š çŸ¥è¯†åº“è®¾ç½®ç»“æœ:")
        print(f"  GraphRAGçŠ¶æ€: {setup_result['graph_rag_status']}")
        print(f"  RAPTORçŠ¶æ€: {setup_result['raptor_status']}")
        print(f"  å¤„ç†æ–‡æ¡£æ•°: {setup_result['total_documents']}")
        print(f"  è®¾ç½®æ—¶é—´: {setup_result['setup_time']:.2f}ç§’")
        
        if setup_result['errors']:
            print(f"  é”™è¯¯ä¿¡æ¯: {setup_result['errors']}")
        
        # 4. æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        print("\nğŸ” ç³»ç»ŸçŠ¶æ€æ£€æŸ¥:")
        status = system.get_system_status()
        
        print(f"  ç³»ç»Ÿåˆå§‹åŒ–: {'âœ…' if status['is_initialized'] else 'âŒ'}")
        print(f"  çŸ¥è¯†åº“å¤§å°: {status['knowledge_base_size']} æ–‡æ¡£")
        print(f"  GraphRAG: {status['components']['graph_rag']['nodes']} èŠ‚ç‚¹, {status['components']['graph_rag']['edges']} è¾¹")
        print(f"  RAPTOR: {status['components']['raptor_tree']['total_nodes']} æ€»èŠ‚ç‚¹, {status['components']['raptor_tree']['root_nodes']} æ ¹èŠ‚ç‚¹")
        print(f"  Agent-RAG: {status['components']['agent_rag']['registered_tools']} æ³¨å†Œå·¥å…·")
        
        # 5. æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯Transformeræ¶æ„ï¼Œå®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ",
            "GraphRAGå’ŒRAPTORæŠ€æœ¯æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "å¤§è¯­è¨€æ¨¡å‹æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ"
        ]
        
        print(f"\nğŸ” å¼€å§‹æµ‹è¯•æŸ¥è¯¢ (å…±{len(test_queries)}ä¸ª)...")
        print("=" * 60)
        
        for i, query in enumerate(test_queries, 1):
            print(f"\nğŸ“ æµ‹è¯•æŸ¥è¯¢ {i}: {query}")
            print("-" * 50)
            
            # æ‰§è¡Œå¤šæ¨¡å¼æŸ¥è¯¢
            result = system.multi_modal_query(
                query, 
                use_graph_rag=True, 
                use_raptor=True, 
                use_agent=True
            )
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            print(f"\nğŸ“Š æŸ¥è¯¢ç»“æœæ‘˜è¦:")
            print(f"  ä½¿ç”¨æ¨¡å¼: {', '.join(result['modes_used'])}")
            print(f"  æ€»æ‰§è¡Œæ—¶é—´: {result['total_execution_time']:.2f}ç§’")
            
            # æ˜¾ç¤ºå„æ¨¡å¼ç½®ä¿¡åº¦
            if result['confidence_scores']:
                print(f"  ç½®ä¿¡åº¦åˆ†æ•°:")
                for mode, score in result['confidence_scores'].items():
                    print(f"    {mode}: {score:.3f}")
            
            # æ˜¾ç¤ºé”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if result['errors']:
                print(f"  é”™è¯¯: {result['errors']}")
            
            # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
            print(f"\nğŸ’¡ èåˆç­”æ¡ˆ:")
            print(f"  {result['final_answer']}")
            
            if i < len(test_queries):
                print("\n" + "="*30 + " åˆ†éš”çº¿ " + "="*30)
        
        # 6. æ€§èƒ½ç»Ÿè®¡
        print(f"\nğŸ“ˆ æ¼”ç¤ºå®Œæˆç»Ÿè®¡:")
        print(f"  ç³»ç»Ÿåˆå§‹åŒ–: âœ…")
        print(f"  çŸ¥è¯†åº“æ„å»º: âœ…")
        print(f"  æµ‹è¯•æŸ¥è¯¢æ•°: {len(test_queries)}")
        print(f"  æ¼”ç¤ºçŠ¶æ€: æˆåŠŸå®Œæˆ")
        
        return True
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        return False
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:")
        print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"  é”™è¯¯ä¿¡æ¯: {str(e)}")
        print(f"\nğŸ“‹ é”™è¯¯è¿½è¸ª:")
        traceback.print_exc()
        return False


def run_simple_demo():
    """è¿è¡Œç®€åŒ–æ¼”ç¤º"""
    
    print("ğŸ¯ å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼")
    print("=" * 40)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        system = IntegratedRAGSystem()
        
        # ç®€å•æ–‡æ¡£
        simple_docs = [
            {
                "id": "simple1",
                "title": "AIåŸºç¡€",
                "content": "äººå·¥æ™ºèƒ½æ˜¯è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æŠ€æœ¯ã€‚æœºå™¨å­¦ä¹ æ˜¯å…¶é‡è¦åˆ†æ”¯ã€‚",
                "source": "ç®€åŒ–æ•™ç¨‹"
            }
        ]
        
        # è®¾ç½®çŸ¥è¯†åº“
        system.setup_knowledge_base(simple_docs)
        
        # ç®€å•æŸ¥è¯¢
        query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
        result = system.multi_modal_query(query)
        
        print(f"\næŸ¥è¯¢: {query}")
        print(f"ç­”æ¡ˆ: {result['final_answer']}")
        print(f"æ¨¡å¼: {', '.join(result['modes_used'])}")
        
        return True
        
    except Exception as e:
        print(f"ç®€åŒ–æ¼”ç¤ºå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸŒŸ RAG+Agentèåˆç³»ç»Ÿæ¼”ç¤ºç¨‹åº")
    print("æ¬¢è¿ä½“éªŒä¸‹ä¸€ä»£æ™ºèƒ½é—®ç­”ç³»ç»Ÿ!")
    print("=" * 60)
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    demo_mode = "comprehensive"  # é»˜è®¤å®Œæ•´æ¼”ç¤º
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--simple":
            demo_mode = "simple"
        elif sys.argv[1] == "--help":
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python demo.py          # å®Œæ•´æ¼”ç¤º")
            print("  python demo.py --simple # ç®€åŒ–æ¼”ç¤º")
            print("  python demo.py --help   # æ˜¾ç¤ºå¸®åŠ©")
            return
    
    try:
        if demo_mode == "simple":
            success = run_simple_demo()
        else:
            success = run_comprehensive_demo()
        
        if success:
            print(f"\nğŸ‰ æ¼”ç¤ºæˆåŠŸå®Œæˆ!")
            print("æ„Ÿè°¢æ‚¨ä½“éªŒRAG+Agentèåˆç³»ç»Ÿ!")
        else:
            print(f"\nâš ï¸  æ¼”ç¤ºæœªèƒ½å®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºå¼‚å¸¸ç»ˆæ­¢:")
        print(f"é”™è¯¯: {e}")
        traceback.print_exc()
    
    finally:
        print(f"\nğŸ‘‹ æ¼”ç¤ºç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()