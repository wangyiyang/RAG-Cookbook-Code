# æ·±åº¦RAGç¬”è®°02 - æ•°æ®ç´¢å¼•ä»£ç å®ç°

æœ¬ç›®å½•åŒ…å«æ·±åº¦RAGç¬”è®°ç¬¬02ç¯‡ã€Šæ•°æ®ç´¢å¼•é˜¶æ®µæ·±åº¦è§£æã€‹çš„å®Œæ•´ä»£ç å®ç°ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
code/ch02/
â”œâ”€â”€ README.md                    # ä»£ç è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ semantic_chunker.py         # æ™ºèƒ½åˆ†å‰²æ¨¡å—
â”œâ”€â”€ embedding_optimizer.py      # å‘é‡åµŒå…¥ä¼˜åŒ–æ¨¡å—
â””â”€â”€ hnsw_index.py               # HNSWå‘é‡ç´¢å¼•å®ç°
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
pip install numpy pandas scikit-learn sentence-transformers
pip install paddleocr python-docx beautifulsoup4 psutil
```

### 2. åŸºæœ¬ä½¿ç”¨

```python
from semantic_chunker import SemanticAwareChunker
from embedding_optimizer import HighPerformanceEmbedding
from quality_monitor import IndexQualityMonitor

# 1. æ™ºèƒ½åˆ†å‰²
text = "ä½ çš„æ–‡æ¡£å†…å®¹"  # å‡è®¾å·²æœ‰æ–‡æ¡£æ–‡æœ¬
chunker = SemanticAwareChunker(target_size=512)
chunks = chunker.intelligent_chunking(text)

# 2. å‘é‡åµŒå…¥
embedder = HighPerformanceEmbedding()
embeddings = embedder.batch_encode_with_optimization(chunks)

# 3. è´¨é‡ç›‘æ§
monitor = IndexQualityMonitor()
quality = monitor.evaluate_quality([text], chunks)
print(f"è´¨é‡è¯„çº§: {quality['quality_grade']}")
```

## ğŸ“‹ æ¨¡å—è¯´æ˜

### semantic_chunker.py
- **åŠŸèƒ½**: åŸºäºè¯­ä¹‰çš„æ™ºèƒ½æ–‡æ¡£åˆ†å‰²
- **æ ¸å¿ƒç®—æ³•**: è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æã€è¾¹ç•Œè¯†åˆ«ã€é‡å å¤„ç†
- **æ”¯æŒç­–ç•¥**: å›ºå®šé•¿åº¦ã€è¯­ä¹‰æ„ŸçŸ¥ã€æ»‘åŠ¨çª—å£

### embedding_optimizer.py
- **åŠŸèƒ½**: é«˜æ€§èƒ½å‘é‡åµŒå…¥è®¡ç®—å’Œè´¨é‡éªŒè¯
- **ä¼˜åŒ–ç‰¹æ€§**: æ‰¹é‡å¤„ç†ã€ç¼“å­˜æœºåˆ¶ã€å»é‡ä¼˜åŒ–
- **è´¨é‡è¯„ä¼°**: è¯­ä¹‰å‡†ç¡®æ€§ã€æŠ€æœ¯æŒ‡æ ‡ã€ç»¼åˆè¯„åˆ†

### hnsw_index.py
- **åŠŸèƒ½**: HNSWç®—æ³•çš„å®Œæ•´å®ç°
- **æ ¸å¿ƒç‰¹æ€§**: å¤šå±‚å›¾ç»“æ„ã€å¯å‘å¼é‚»å±…é€‰æ‹©ã€åŠ¨æ€æ’å…¥
- **æ€§èƒ½ä¼˜åŠ¿**: O(log N)æœç´¢å¤æ‚åº¦ã€é«˜å¬å›ç‡

### quality_monitor.py
- **åŠŸèƒ½**: å…¨é¢çš„ç´¢å¼•è´¨é‡ç›‘æ§å’Œæ€§èƒ½åˆ†æ
- **ç›‘æ§ç»´åº¦**: ä¿¡æ¯å®Œæ•´æ€§ã€è¯­ä¹‰ä¸€è‡´æ€§ã€æ£€ç´¢ç²¾åº¦
- **æŠ¥å‘ŠåŠŸèƒ½**: è´¨é‡ç­‰çº§è¯„å®šã€ä¼˜åŒ–å»ºè®®ç”Ÿæˆ

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: ä¼ä¸šæ–‡æ¡£çŸ¥è¯†åº“æ„å»º
```python
# å¤„ç†ä¼ä¸šå†…éƒ¨æ–‡æ¡£
chunker = SemanticAwareChunker(target_size=1024, overlap_ratio=0.1)

for text in document_texts:  # å‡è®¾å·²æœ‰æ–‡æ¡£æ–‡æœ¬
    chunks = chunker.intelligent_chunking(text)
    # åç»­å¤„ç†...
```

### åœºæ™¯2: å¤§è§„æ¨¡æ–‡æ¡£æ‰¹é‡å¤„ç†
```python
# é«˜æ€§èƒ½æ‰¹é‡å¤„ç†
embedder = HighPerformanceEmbedding("BAAI/bge-large-zh")
all_chunks = []  # æ”¶é›†æ‰€æœ‰æ–‡æ¡£ç‰‡æ®µ

# æ‰¹é‡è®¡ç®—åµŒå…¥ï¼Œè‡ªåŠ¨ä¼˜åŒ–æ€§èƒ½
embeddings = embedder.batch_encode_with_optimization(all_chunks, batch_size=64)
```

### åœºæ™¯3: è´¨é‡ç›‘æ§å’Œä¼˜åŒ–
```python
# æŒç»­è´¨é‡ç›‘æ§
monitor = IndexQualityMonitor()
quality_result = monitor.evaluate_quality(original_docs, chunks)

if quality_result['overall_score'] < 0.8:
    print("è´¨é‡ä¸è¾¾æ ‡ï¼Œéœ€è¦ä¼˜åŒ–:")
    for recommendation in quality_result['recommendations']:
        print(f"- {recommendation}")
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

åœ¨æµ‹è¯•ç¯å¢ƒä¸‹çš„æ€§èƒ½è¡¨ç°ï¼š

| æŒ‡æ ‡ | æ€§èƒ½ | è¯´æ˜ |
|------|------|------|
| æ–‡æ¡£å¤„ç†é€Ÿåº¦ | 100+ docs/min | PDF/DOCXæ··åˆæ–‡æ¡£ |
| åµŒå…¥è®¡ç®—é€Ÿåº¦ | 1000+ chunks/min | BGE-large-zhæ¨¡å‹ |
| HNSWæœç´¢å»¶è¿Ÿ | <5ms | 100ä¸‡å‘é‡è§„æ¨¡ |
| å†…å­˜å ç”¨ | åŸæ•°æ®1.2å€ | åŒ…å«ç´¢å¼•ç»“æ„ |

## âš™ï¸ é…ç½®é€‰é¡¹

### åˆ†å‰²é…ç½®
```python
chunker = SemanticAwareChunker(
    target_size=512,           # ç›®æ ‡ç‰‡æ®µé•¿åº¦
    overlap_ratio=0.1,         # é‡å æ¯”ä¾‹
    similarity_threshold=0.7   # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
)
```

### åµŒå…¥é…ç½®
```python
embedder = HighPerformanceEmbedding(
    model_name="BAAI/bge-large-zh",  # åµŒå…¥æ¨¡å‹
    device="cuda",                   # è®¡ç®—è®¾å¤‡
    batch_size=64                    # æ‰¹å¤„ç†å¤§å°
)
```

### HNSWé…ç½®
```python
index = HNSWIndex(
    dimension=768,           # å‘é‡ç»´åº¦
    max_m=16,               # æœ€å¤§è¿æ¥æ•°
    ef_construction=200     # æ„å»ºæ—¶æœç´¢å®½åº¦
)
```

## ğŸ”§ è‡ªå®šä¹‰æ‰©å±•

### å®ç°è‡ªå®šä¹‰åˆ†å‰²ç­–ç•¥
```python
class CustomChunker(SemanticAwareChunker):
    def domain_specific_chunking(self, text):
        # å®ç°é¢†åŸŸç‰¹å®šçš„åˆ†å‰²é€»è¾‘
        pass
```

### é›†æˆå…¶ä»–å‘é‡æ•°æ®åº“
```python
class PineconeIntegration:
    def store_vectors(self, embeddings, metadata):
        # å®ç°Pineconeå­˜å‚¨é€»è¾‘
        pass
```

## ğŸ“ˆ ç›‘æ§å’Œè°ƒä¼˜

### æ€§èƒ½ç›‘æ§
```python
from quality_monitor import PerformanceMonitor

monitor = PerformanceMonitor()
metrics = monitor.collect_metrics(processing_stats)
report = monitor.generate_performance_report()
```

### è´¨é‡è°ƒä¼˜
1. **åˆ†å‰²ç­–ç•¥è°ƒä¼˜**: æ ¹æ®æ–‡æ¡£ç±»å‹è°ƒæ•´target_sizeå’Œoverlap_ratio
2. **åµŒå…¥æ¨¡å‹é€‰æ‹©**: æ ¹æ®è¯­è¨€å’Œé¢†åŸŸé€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒæ¨¡å‹
3. **ç´¢å¼•å‚æ•°ä¼˜åŒ–**: æ ¹æ®æ•°æ®è§„æ¨¡å’Œç²¾åº¦è¦æ±‚è°ƒæ•´HNSWå‚æ•°

## ğŸ”— ç›¸å…³èµ„æº

- [æ·±åº¦RAGç¬”è®°01: æ ¸å¿ƒæ¦‚å¿µä¸è¯ç”ŸèƒŒæ™¯](../ch01/)
- [æ·±åº¦RAGç¬”è®°03: æ™ºèƒ½æ£€ç´¢æ ¸å¿ƒæŠ€æœ¯](../ch03/)
- [BGEåµŒå…¥æ¨¡å‹](https://huggingface.co/BAAI/bge-large-zh)
- [HNSWè®ºæ–‡](https://arxiv.org/abs/1603.09320)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›ä»£ç å®ç°ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬ä»£ç éµå¾ªMITè®¸å¯è¯ã€‚